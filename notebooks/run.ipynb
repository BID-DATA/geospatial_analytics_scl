{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2ad9d4",
   "metadata": {},
   "source": [
    "# Social infrastructure in LAC\n",
    "\n",
    "**Objetive:** <br>\n",
    "The following notebook runs all the social infrastructure analysis. <br>\n",
    "\n",
    "Author: Laura Goyeneche, Consultant SPH, lauragoy@iadb.org <br>\n",
    "Created: March 20, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7404ca7",
   "metadata": {},
   "source": [
    "## 1. Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935d861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install arcgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175bb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Import modules \n",
    "import fiona \n",
    "from utils import * \n",
    "\n",
    "from h3 import geo_to_h3, h3_to_geo_boundary\n",
    "from shapely.geometry import Polygon\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8028f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcgis\n",
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369d246",
   "metadata": {},
   "source": [
    "## 2. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd7e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine input values\n",
    "data   = get_iadb()\n",
    "codes  = data.isoalpha3.tolist()\n",
    "groups = [\"total_population\",\"women\",\"men\",\"children_under_five\",\"youth_15_24\",\"elderly_60_plus\",\"women_of_reproductive_age_15_49\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ef270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefiles \n",
    "shp1 = get_country_shp(level = 1)\n",
    "shp2 = get_country_shp(level = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2b047",
   "metadata": {},
   "source": [
    "## 3. Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Inputs\n",
    "group = \"total_population\"\n",
    "code  = \"BRA\"\n",
    "\n",
    "# Get population data \n",
    "file = get_population(data, code, group)\n",
    "\n",
    "# Save data \n",
    "file.to_csv(f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\", compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total population by adminsitrative level\n",
    "group        = \"total_population\"\n",
    "pop_shp1_lac = []\n",
    "pop_shp2_lac = []\n",
    "\n",
    "for code in codes[:-1]: \n",
    "    print(code)\n",
    "    # Population Meta-level\n",
    "    population = pd.read_csv(f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\")\n",
    "    geometry   = gpd.points_from_xy(population['longitude'], population['latitude'])\n",
    "    population = gpd.GeoDataFrame(population.copy(), geometry = geometry, crs = 4326)\n",
    "\n",
    "    # Population in admin level 1\n",
    "    pop_shp1 = gpd.sjoin(shp1[shp1.ADM0_PCODE == code], population)\n",
    "    pop_shp1 = pop_shp1[[\"ADM1_PCODE\",\"population\"]]\n",
    "    pop_shp1 = pop_shp1.groupby(\"ADM1_PCODE\").sum().reset_index()\n",
    "    \n",
    "    # Population in admin level 2\n",
    "    pop_shp2 = gpd.sjoin(shp2[shp2.ADM0_PCODE == code], population)\n",
    "    pop_shp2 = pop_shp2[[\"ADM2_PCODE\",\"population\"]]\n",
    "    pop_shp2 = pop_shp2.groupby(\"ADM2_PCODE\").sum().reset_index()\n",
    "    \n",
    "    # Append to master lists\n",
    "    pop_shp1_lac.append(pop_shp1)\n",
    "    pop_shp2_lac.append(pop_shp2)\n",
    "\n",
    "pop_shp1_lac = pd.concat(pop_shp1_lac)\n",
    "pop_shp2_lac = pd.concat(pop_shp2_lac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd47c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export population datasets\n",
    "    # Admin 1\n",
    "shp1_ = shp1.drop(columns = \"geometry\")\n",
    "shp1_ = shp1_.merge(pop_shp1_lac, on = \"ADM1_PCODE\", how = \"left\")\n",
    "shp1_.to_csv(f\"../data/0-raw/population/{group}/population-adm1.csv\", index = False)\n",
    "\n",
    "    # Admin 2\n",
    "shp2_ = shp2.drop(columns = \"geometry\")\n",
    "shp2_ = shp2_.merge(pop_shp2_lac, on = \"ADM2_PCODE\", how = \"left\")\n",
    "shp2_.to_csv(f\"../data/0-raw/population/{group}/population-adm2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN\n",
    "# Datafile save in wrong format \n",
    "%%capture\n",
    "for group in groups:\n",
    "    for code in codes[:1]:\n",
    "        data = f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\"\n",
    "        data = pd.read_csv(data)\n",
    "        path = \"Development Data Partnership/Facebook - High resolution population density map/public-fb-data/csv/\"\n",
    "        path = scldatalake + f\"{path}/{code.upper()}/{code}_{group}.csv.gz\"\n",
    "        data.to_csv(path, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94778f18",
   "metadata": {},
   "source": [
    "## 4. Amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0fe04a",
   "metadata": {},
   "source": [
    "### 4.1. Extract coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda25ef",
   "metadata": {},
   "source": [
    "#### Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset \n",
    "client  = Socrata(\"www.datos.gov.co\", None)\n",
    "request = client.get(\"c36g-9fc2\", limit = 100000)\n",
    "file    = pd.DataFrame.from_records(request)\n",
    "file    = file[file.claseprestador == 'Instituciones Prestadoras de Servicios de Salud - IPS']\n",
    "file    = file.drop_duplicates()\n",
    "file    = file.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define address\n",
    "file[\"address\"] = file[['direcci_nsede','departamentodededesc','municipiosededesc']].agg(' '.join, axis = 1)\n",
    "file[\"address\"] = file.address.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find coordinates \n",
    "coordinates = []\n",
    "for name in file.address:\n",
    "    coordinates_ = get_coordinates(name, \"COL\")\n",
    "    coordinates.append(coordinates_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a38b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select coordinates and find lat,lon\n",
    "lat, lon = [], []\n",
    "for i in range(0,len(coordinates)):\n",
    "    coordinate = coordinates[i]\n",
    "    if len(coordinate) > 1:\n",
    "        coordinate = [j for j in coordinate if file.departamentodededesc[i]      in j[\"place_name\"]]\n",
    "        coordinate = [j for j in coordinate if file.municipiosededesc[i].title() in j[\"place_name\"]] \n",
    "        if len(coordinate) > 1:\n",
    "            coordinate = coordinate[:1]\n",
    "    try:\n",
    "        coordinate = coordinate[0]['geometry']\n",
    "        lon_, lat_ = coordinate['coordinates']\n",
    "    except:\n",
    "        lon_, lat_ = '', ''\n",
    "    \n",
    "    lat.append(lat_)\n",
    "    lon.append(lon_) \n",
    "\n",
    "file['latitute']  = lat\n",
    "file['longitude'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to SCL\n",
    "file.to_csv(f\"{scldatalake}Geospatial infrastructure/Healthcare Facilities/official/COL/reps-ips.csv\", index = False, encoding = 'uft-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dea786",
   "metadata": {},
   "source": [
    "### 4.2. Master infrastrastructure table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b4cfd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "amenities = ['healthcare','financial']\n",
    "groups    = [\"official\",\"public\"]\n",
    "for group in groups[:1]:\n",
    "    for amenity in amenities[:1]:\n",
    "        # Get infrastructure data\n",
    "        infrastructure = get_amenity(amenity, group)\n",
    "        \n",
    "        if len(infrastructure) > 0:\n",
    "            infrastructure.to_csv(f\"../data/0-raw/infrastructure/{amenity}_facilities_{group}.csv\")\n",
    "            infrastructure.to_csv(f\"{scldatalake}Geospatial infrastructure/{amenity.title()} Facilities/{amenity}_facilities_{group}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa54639",
   "metadata": {},
   "source": [
    "## 4. Isochrones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079185c9",
   "metadata": {},
   "source": [
    "### 4.1 Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b00417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 minutes\n",
      "CPU times: user 16.9 s, sys: 438 ms, total: 17.3 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Inputs\n",
    "amenity = 'healthcare'\n",
    "minute  = 30\n",
    "profile = 'driving'\n",
    "group   = \"official\"\n",
    "code    = \"HTI\"\n",
    "\n",
    "# Get isochrones per amenity\n",
    "print(f\"{minute} minutes\")\n",
    "isochrone = get_isochrones_country(code, amenity, minute, profile, group)\n",
    "isochrone['geometry'] = isochrone.geometry.buffer(0)\n",
    "isochrones = isochrone.dissolve()\n",
    "\n",
    "# Export isochrone\n",
    "isochrones.to_file(f\"../data/1-isochrones/{amenity}/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c98b1",
   "metadata": {},
   "source": [
    "### 4.2 Financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# Inputs\n",
    "amenity = 'financial'\n",
    "group   = \"public\"\n",
    "minute  = 30\n",
    "profile = 'driving'\n",
    "code    = \"GUY\"\n",
    "\n",
    "# Get isochrones per amenity\n",
    "isochrone  = get_isochrones_country(code, amenity, minute, profile, group)\n",
    "isochrones = isochrone.dissolve()\n",
    "\n",
    "# Export isochrone \n",
    "isochrones.to_file(f\"../data/1-isochrones/{amenity}/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each financial service type\n",
    "for category in isochrone.amenity.unique():\n",
    "    # Create one multipolygon\n",
    "    isochrones = isochrone[isochrone.amenity == category]\n",
    "    isochrones = isochrones.dissolve()\n",
    "\n",
    "    # Export isochrone \n",
    "    isochrones.to_file(f\"../data/1-isochrones/{amenity}/{category}/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c3c814",
   "metadata": {},
   "source": [
    "### 4.3 Regional shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c887c77",
   "metadata": {},
   "source": [
    "#### 4.3.1 Individual regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "amenity    = \"healthcare\"\n",
    "profile    = \"driving\"\n",
    "minute     = 30\n",
    "group      = \"official\"\n",
    "isochrones = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b47b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of country-isochrones\n",
    "# Note: Try/except for countries without isochrones\n",
    "for code in codes:\n",
    "    try:\n",
    "        with fiona.Env(OGR_GEOJSON_MAX_OBJ_SIZE = 2000):  \n",
    "            isochrone = gpd.read_file(f\"../data/1-isochrones/{amenity}/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\")\n",
    "            isochrones.append(isochrone)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0322c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create regional isochrone\n",
    "isochrones = pd.concat(isochrones)\n",
    "isochrones = isochrones.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export isochrones \n",
    "isochrones.to_file(f\"../data/1-isochrones/region/{amenity}/{group}/{minute}-min/{amenity}-{profile}-{minute}.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4867e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (20,8))\n",
    "shp1.plot(ax = ax, color = \"#D6D6D6\")\n",
    "isochrones.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d088a70",
   "metadata": {},
   "source": [
    "#### 4.3.2 Joint regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0014e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs \n",
    "amenity = \"healthcare\"\n",
    "profile = \"driving\"\n",
    "region_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create joint shapefile\n",
    "minutes = [15, 30, 45]\n",
    "for minute in minutes:\n",
    "    temp = gpd.read_file(f\"../data/1-isochrones/region/{amenity}-{profile}-{minute}.shp\")\n",
    "    temp[\"minute\"] = minute\n",
    "    region_.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e730030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regional isochrone\n",
    "region_ = pd.concat(region_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export isochrones \n",
    "region_.to_file(f\"../data/1-isochrones/{amenity}-{profile}.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a399249",
   "metadata": {},
   "source": [
    "## 5. Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe10a1",
   "metadata": {},
   "source": [
    "### 5.1. Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# DAVID ESTE!!!\n",
    "# Inputs\n",
    "amenity = 'healthcare'\n",
    "minute  = 30\n",
    "profile = 'driving'\n",
    "group   = \"official\"\n",
    "code    = \"BRA\"\n",
    "\n",
    "# Create shapefile\n",
    "adm2_, h3_ = get_coverage(code, amenity, profile, minute, group)\n",
    "\n",
    "# Export isochrone \n",
    "#adm2_.to_file(f\"../data/2-coverage/{amenity}/adm2/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")\n",
    "#h3_  .to_file(f\"../data/2-coverage/{amenity}/h3/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\"  , driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bda6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 32s, sys: 75.9 ms, total: 7min 32s\n",
      "Wall time: 7min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Inputs\n",
    "amenity = 'healthcare'\n",
    "minute  = 30\n",
    "profile = 'driving'\n",
    "group   = \"official\"\n",
    "code    = \"DOM\"\n",
    "\n",
    "# Create shapefile\n",
    "adm2_, h3_ = get_coverage(code, amenity, profile, minute, group)\n",
    "\n",
    "# Export isochrone \n",
    "adm2_.to_file(f\"../data/2-coverage/{amenity}/adm2/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")\n",
    "h3_  .to_file(f\"../data/2-coverage/{amenity}/h3/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\"  , driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7915402",
   "metadata": {},
   "source": [
    "### 5.2. Financieros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "amenity    = 'financial'\n",
    "subamenity = {\"all\":[\"\",\"total\"],\"atm\":[\"atm\",\"atm\"],\"bank\":[\"bank\",\"bank\"],\"bureau_de_change\":[\"bureau_de_change\",\"bureau_de_change\"]}\n",
    "minute     = 30\n",
    "profile    = 'driving'\n",
    "code       = \"BRA\"\n",
    "\n",
    "#for amenity_ in subamenity.keys():\n",
    "for amenity_ in [\"bank\",\"bureau_de_change\"]:\n",
    "    # Labels \n",
    "    amenity_input  = f\"{amenity}/{subamenity[amenity_][0]}\"\n",
    "    amenity_input  = re.sub(\"/$\",\"\",amenity_input)\n",
    "    amenity_output = f\"{amenity}/{subamenity[amenity_][1]}\"\n",
    "\n",
    "    # Create shapefile\n",
    "    adm2_, h3_ = get_coverage(code, amenity_input, profile, minute)\n",
    "\n",
    "    # Export isochrone\n",
    "    adm2_.to_file(f\"../data/2-coverage/{amenity_output}/adm2/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")\n",
    "    h3_  .to_file(f\"../data/2-coverage/{amenity_output}/h3/{code}-{profile}-{minute}.geojson\"  , driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb33c32",
   "metadata": {},
   "source": [
    "### 5.3. Create regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a1783f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefile ADMIN-2\n",
    "file = f\"Geospatial Basemaps/Cartographic Boundary Files/LAC-26/region/level-2/lac-level-2.shp\"\n",
    "path = scldatalake + file\n",
    "shp  = gpd.read_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad83853",
   "metadata": {},
   "source": [
    "#### 5.3.1. Healthcare amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0294a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 25s, sys: 1.42 s, total: 4min 26s\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Create public and official regional shp\n",
    "# Inputs \n",
    "unit  = \"adm2\"\n",
    "group = \"official\"\n",
    "min_  = 30\n",
    "\n",
    "# Append datasets\n",
    "path  = f\"../data/2-coverage/healthcare/{unit}/{group}/{min_}-min\"\n",
    "file  = os.listdir(path)\n",
    "file  = [name for name in file if \"geojson\" in name]\n",
    "shp_  = [gpd.read_file(f\"{path}/{name}\") for name in file]\n",
    "lac   = gpd.pd.concat(shp_).pipe(gpd.GeoDataFrame)\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/{group}/lac-driving-{min_}-min.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Join public and official amenities\n",
    "unit     = \"h3\"\n",
    "minute   = 30\n",
    "\n",
    "# Import data\n",
    "public   = gpd.read_file(f\"../data/2-coverage/healthcare/{unit}/public/lac-driving-{minute}-min.geojson\")\n",
    "official = gpd.read_file(f\"../data/2-coverage/healthcare/{unit}/official/lac-driving-{minute}-min.geojson\")\n",
    "\n",
    "# Rename variables \n",
    "# Note: rename variables for Atlas IADB (max elength 11 letters)\n",
    "names    = {\"pop_cov\":\"ncov\",\"pop_uncov\":\"nuncov\",\"per_cov\":\"ratecov\",\"per_uncov\":\"rateunc\"}\n",
    "public   = public  .rename(columns = names)\n",
    "official = official.rename(columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf948fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "if unit == \"h3\":\n",
    "    shp0     = get_country_shp(level = 0)   \n",
    "    public   = gpd.sjoin(public  , shp0)\n",
    "    official = gpd.sjoin(official, shp0)\n",
    "    \n",
    "    public   = public  .drop(columns = \"index_right\")\n",
    "    official = official.drop(columns = \"index_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61779978",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create new featutes \n",
    "    # Public data\n",
    "public[\"percov\"] = public.ncov   * 100 / public.groupby(\"ADM0_PCODE\").ncov  .transform(\"sum\")\n",
    "public[\"perunc\"] = public.nuncov * 100 / public.groupby(\"ADM0_PCODE\").nuncov.transform(\"sum\")\n",
    "\n",
    "    # Official data\n",
    "official[\"percov\"] = official.ncov   * 100 / official.groupby(\"ADM0_PCODE\").ncov  .transform(\"sum\")\n",
    "official[\"perunc\"] = official.nuncov * 100 / official.groupby(\"ADM0_PCODE\").nuncov.transform(\"sum\")\n",
    "\n",
    "# Define columns names\n",
    "colnames   = public.columns.tolist()\n",
    "vars_      = ['ncov','nuncov','ratecov','rateunc','percov','perunc']\n",
    "pub_vars   = [f\"{name}_pub\" if name in vars_ else name for name in colnames]\n",
    "off_vars   = [f\"{name}_off\" if name in vars_ else name for name in colnames]\n",
    "\n",
    "# Rename variables\n",
    "public  .columns = pub_vars\n",
    "official.columns = off_vars\n",
    "\n",
    "# Drop columns from official dataset\n",
    "idvar    = \"ADM2_PCODE\" if unit == \"adm2\" else \"hex_id\"\n",
    "off_vars = [idvar] + [name for name in official.columns if \"_off\" in name] \n",
    "official = official[off_vars]\n",
    "\n",
    "# Merge \n",
    "lac = public.merge(official, on = idvar, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add poverty data and adjust names if admin-2\n",
    "# TODO: not neccesary, temporary, remove in other version\n",
    "if unit == \"adm2\":\n",
    "    # Import poverty data \n",
    "    path    = \"Data Projects/Official Subnational Poverty Rates/lac-level-2.csv\"\n",
    "    poverty = pd.read_csv(f\"s3://{sclbucket}/{path}\", encoding='latin-1')\n",
    "    poverty = poverty[[\"ADM2_PCODE\",\"POVERTY_RATE_TOT\",\"POVERTY_NUM_TOT\",\"POVERTY_SOURCE\"]]\n",
    "    poverty = poverty.rename(columns = {\"POVERTY_RATE_TOT\":\"pov_rate\",\"POVERTY_NUM_TOT\":\"pov_num\",\"POVERTY_SOURCE\":\"pov_source\"})\n",
    "    \n",
    "    # Merge \n",
    "    lac = lac.merge(poverty, on = \"ADM2_PCODE\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "lac = lac.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export data (GeoJSON, .shp, .csv)\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.geojson\", driver = \"GeoJSON\")\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.shp\")\n",
    "lac.drop(columns = \"geometry\").to_csv(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24aeb99",
   "metadata": {},
   "source": [
    "## 6. Upload to ATLAS IDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "502f33d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please sign in to your GIS and paste the code that is obtained below.\n",
      "If a web browser does not automatically open, please navigate to the URL below yourself instead.\n",
      "Opening web browser to navigate to: https://atlas.iadb.org/portal/sharing/rest/oauth2/authorize?response_type=code&client_id=zrNAstM1cFmGOJ5E&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&state=GyOZgzUApcVxyIhKfrWyfoljVCWflI&allow_verification=false\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter code obtained on signing in using SAML:  ············································································································································································································································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages/urllib3/connectionpool.py:1050: InsecureRequestWarning: Unverified HTTPS request is being made to host 'atlas.iadb.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    }
   ],
   "source": [
    "# Log-in into the portal\n",
    "url = 'https://atlas.iadb.org/portal/home'\n",
    "id_ = 'zrNAstM1cFmGOJ5E' \n",
    "gis = GIS(url, client_id = id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da4185f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: LAURAGOY@iadb.org\n",
      "Role: org_publisher\n"
     ]
    }
   ],
   "source": [
    "user = gis.users.me\n",
    "print(f\"Username: {user.username}\")\n",
    "print(f\"Role: {user.role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e01873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file \n",
    "path = \"Geospatial Basemaps/Connectivity/fixed/LAC-26/admin-level/fixed_connectivity_adm2_2023_q2.csv\"\n",
    "obj  = s3.get_object(Bucket = sclbucket, Key = path)\n",
    "file = pd.read_csv(obj['Body'], encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84fa6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gdf \n",
    "shp2_ = shp2.merge(file[['ADM2_PCODE','avg_d_mbps_wt','avg_u_mbps_wt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2153eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Save gdf\n",
    "name = path.split('/')[-1]\n",
    "name = name.replace('.csv','.shp')\n",
    "shp2_.to_file(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51975df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Zipfile\n",
    "with ZipFile(f'{name[:-4]}.zip','w') as zip_object:\n",
    "    zip_object.write(f'{name[:-4]}.shp')\n",
    "    zip_object.write(f'{name[:-4]}.shx')\n",
    "    zip_object.write(f'{name[:-4]}.dbf')\n",
    "    zip_object.write(f'{name[:-4]}.prj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9db7d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file properties\n",
    "prop = {\"title\": name[:-4],\n",
    "        \"type\" : \"Shapefile\",\n",
    "        \"tags\" : \"conectividad, admin-2, Latin America and Caribbean, Ookla\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61ea8e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fixed_connectivity_adm2_2023_q2.zip'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.replace(\".shp\",\".zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af4da0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-ce4b921f6970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create content to publish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".shp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\".zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SPH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages/arcgis/gis/__init__.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, item_properties, data, thumbnail, metadata, owner, folder, item_id, **kwargs)\u001b[0m\n\u001b[1;32m   5975\u001b[0m             \u001b[0;31m# Create an empty Item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5976\u001b[0m             itemid = self._portal.add_item(\n\u001b[0;32m-> 5977\u001b[0;31m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthumbnail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5978\u001b[0m             )\n\u001b[1;32m   5979\u001b[0m             \u001b[0;31m# check the status and commit the final result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages/arcgis/gis/_impl/_portalpy.py\u001b[0m in \u001b[0;36madd_item\u001b[0;34m(self, item_properties, data, thumbnail, metadata, owner, folder)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# If owner isn't specified, use the logged in user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mowner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogged_in_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"username\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;31m# Setup the item path, including the folder, and post to it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Create content to publish\n",
    "item = gis.content.add(prop, data = name.replace(\".shp\",\".zip\"), folder = \"SPH\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
