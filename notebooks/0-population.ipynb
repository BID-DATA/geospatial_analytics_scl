{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25327429",
   "metadata": {},
   "source": [
    "# High Resolution Population Density Maps\n",
    "\n",
    "**Objetive:** <br>\n",
    "The following notebook shows the step-by-step to query and adjust the population layers from Meta and CIESIN pubished in the [HDX](https://data.humdata.org/organization/facebook?q=high%20resolution%20population%20density&ext_page_size=100) data for good portal. <br><br>\n",
    "\n",
    "Author: Laura Goyeneche, Consultant SPH, lauragoy@iadb.org <br>\n",
    "Created: March 20, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc60223",
   "metadata": {},
   "source": [
    "## 1. Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e08a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Libraries\n",
    "import os \n",
    "import re\n",
    "import time\n",
    "import dotenv\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from geopandas.tools import sjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3717d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working environments\n",
    "dotenv.load_dotenv()\n",
    "sclbucket   = os.environ.get(\"sclbucket\")\n",
    "scldatalake = os.environ.get(\"scldatalake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4b8ef",
   "metadata": {},
   "source": [
    "## 2. Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d3196",
   "metadata": {},
   "source": [
    "### 2.1. Country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "603b474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import country names\n",
    "file  = \"Manuals and Standards/IADB country and area codes for statistical use/IADB_country_codes_admin_0.xlsx\"\n",
    "path  = scldatalake + file\n",
    "data  = pd.read_excel(path, engine='openpyxl')\n",
    "\n",
    "# Select rows/columns of interest\n",
    "data = data[~data.iadb_region_code.isna()]\n",
    "data = data[['isoalpha3','country_name_es']]\n",
    "\n",
    "# Replace values\n",
    "data['country_name_en'] = data.country_name_es.str.normalize('NFKD')\n",
    "data.country_name_en    = data.country_name_en.str.encode('ascii', errors = 'ignore')\n",
    "data.country_name_en    = data.country_name_en.str.decode('utf-8')\n",
    "\n",
    "# Replace country names\n",
    "country_ = {\"Belice\":\"Belize\",\n",
    "            \"Bolivia (Estado Plurinacional de)\":\"Bolivia\",\n",
    "            \"Brasil\":\"Brazil\",\n",
    "            \"Venezuela (Republica Bolivariana de)\":\"Venezuela\",\"Republica Dominicana\":\n",
    "            \"Dominican Republic\",\"Trinidad y Tabago\":\n",
    "            \"Trinidad and Tobago\"}\n",
    "data.country_name_en = data.country_name_en.replace(country_)\n",
    "\n",
    "# Sort dataset\n",
    "data = data.sort_values(by = \"isoalpha3\")\n",
    "codes = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16275b82",
   "metadata": {},
   "source": [
    "### 2.2. Population\n",
    "\n",
    "To query a country dataset selected the [iso-alpha3 country code](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3) and select the population group of interest `total_population`, `women`, `men`, `children_under_five`, `youth_15_24`, `elderly_60_plus`, and `women_of_reproductive_age_15_49`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c991c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest population density maps name files \n",
    "# Request HTML content\n",
    "code     = \"COL\"\n",
    "geo      = codes[codes.isoalpha3 == code].country_name_en.values[0].lower().replace(\" \",\"-\")\n",
    "url      = f\"https://data.humdata.org/dataset/{geo}-high-resolution-population-density-maps-demographic-estimates\"\n",
    "response = requests.get(url)\n",
    "html     = response.content\n",
    "soup     = BeautifulSoup(html, \"html5lib\")\n",
    "\n",
    "# Find file names\n",
    "soup     = soup.find_all('ul', attrs = {\"class\":\"hdx-bs3 resource-list\"})\n",
    "soup     = soup[0].find_all('li', attrs = {\"class\":\"resource-item\"})\n",
    "url      = [item.find_all('div', attrs = {\"class\":\"hdx-btn-group hdx-btn-group-fixed\"})[0].find('a')['href'] for item in soup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7025ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing URL\n",
    "url = [item for item in url if \"csv\" in item]\n",
    "url = [f\"https://data.humdata.org{item}\" for item in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddfaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing file names\n",
    "files = []\n",
    "for item in url: \n",
    "    item_ = item.split(\"/\")[-1]\n",
    "    item_ = item_.replace(\"_csv\",\".csv\")\n",
    "    item_ = item_.replace(\".zip\",\".gz\")\n",
    "    item_ = re.sub(\"(_|-)\\d+\", \"\", item_)\n",
    "    item_ = item_.replace(\"population\",\"total_population\")\n",
    "    item_ = item_.replace(\"general\",\"total_population\")\n",
    "    item_ = f\"{code}_{item_}\"\n",
    "    item_ = item_.replace(f\"{code.lower()}_\",\"\")\n",
    "    item_ = item_.replace(f\"_{code.lower()}\",\"\")\n",
    "    item_ = item_.replace(\"elderly_plus\",\"elderly_60_plus\")\n",
    "    item_ = item_.replace(\"youth\",\"youth_15_24\")\n",
    "    item_ = item_.replace(\"women_of_reproductive_age\",\"women_of_reproductive_age_15_49\")\n",
    "    \n",
    "    files.append(item_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629897b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "# Select group of interest\n",
    "group = \"total_population\"\n",
    "item  = [item for item in files if group in item][0]\n",
    "path  = url[files.index(item)] \n",
    "pop   = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa5041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep variables of interest\n",
    "# Keep most recent population estimation \n",
    "temp = [name for name in pop.columns if \"lat\" not in name and \"lon\" not in name]\n",
    "if len(temp) > 1: \n",
    "    if temp[len(temp)-1] > temp[len(temp)-2]:\n",
    "        var_ = temp[len(temp)-1]\n",
    "    else: \n",
    "        var_ = temp[len(temp)-2]\n",
    "else: \n",
    "    var_ = temp[0]\n",
    "\n",
    "# Select variables of interest\n",
    "vars_ = [\"latitude\",\"longitude\",var_]\n",
    "pop   = pop[vars_]\n",
    "pop   = pop.rename(columns = {var_:\"population\"})\n",
    "\n",
    "# Rename variables\n",
    "pop.columns = [re.sub(\"_\\d+\", \"\", name) for name in pop.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae56b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert population .csv to .gpd\n",
    "geometry = gpd.points_from_xy(pop['longitude'], pop['latitude'])\n",
    "pop_geo  = gpd.GeoDataFrame(pop.copy(), geometry = geometry, crs = 4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ba5ce",
   "metadata": {},
   "source": [
    "### 2.2. Country shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18f0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "code = code.lower()\n",
    "file = f\"Geospatial Basemaps/Cartographic Boundary Files/LAC-26/level-0/{code}-level-0.shp\"\n",
    "path = scldatalake + file\n",
    "shp_ = gpd.read_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff029e8",
   "metadata": {},
   "source": [
    "## 3. Map adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9194b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep points inside country/region of interets\n",
    "pop_geo_adj = gpd.clip(pop_geo, shp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b176c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export to Data Lake as .csv.gz \n",
    "file = pop_geo_adj.copy()\n",
    "file = file.drop(columns = \"geometry\")\n",
    "path = \"De3velopment Data Partnership/Facebook - High resolution population density map/public-fb-data/csv/\"\n",
    "path = scldatalake + f\"{path}/{code.upper()}/{item}\"\n",
    "file.to_csv(path, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92852e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6977167, 4)\n",
      "50830740.49238202\n"
     ]
    }
   ],
   "source": [
    "# New data \n",
    "print(pop_geo_adj.shape)\n",
    "print(pop_geo_adj.population.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4d5053e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3523846, 3)\n",
      "48228262.601337105\n"
     ]
    }
   ],
   "source": [
    "# Test update dataset\n",
    "# Antes: 3.5M x 3, 48M\n",
    "temp = \"Development Data Partnership/Facebook - High resolution population density map/public-fb-data/csv/COL/COL_total_population.csv.gz\"\n",
    "temp = scldatalake + temp \n",
    "temp = pd.read_csv(temp, sep = \"\\t\")\n",
    "\n",
    "print(temp.shape)\n",
    "print(temp.population.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
