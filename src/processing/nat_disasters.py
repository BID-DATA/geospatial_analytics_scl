import xml.etree.ElementTree as ETbase = "/Users/lauragoyeneche/Google Drive/My Drive/02-Work/10-IDB Consultant/1-Social Protection & Health/32-IDB Atlas"path = "raw/desinventar/"def get_desinventar(code):    '''    process DesInventar        Parameters    ----------    code : str, optional        country's isoalpha3 code        Returns    -------    pandas.DataFrame        dataframe with # natural disasters by country, year, event type    '''        # Import XML data    # TODO: update path    tree = ET.parse(f'{base}/raw/desinventar/_misc/DI_export_{code.lower()}/DI_export_{code.lower()}.xml')     root = tree.getroot()    xml_ = []    for elem in root.findall('.//fichas/*'):        data_dict = {subelem.tag: subelem.text for subelem in elem}        xml_.append(data_dict)    xml_data = pd.DataFrame(xml_)        # Shapefiles    shp1 = get_country_shp(code, level = 1)    shp2 = get_country_shp(code, level = 2)        # Identify country boundaries    if code in shp2.ADM0_PCODE.unique():        cty_shp = shp2.copy()        level   = 2    else:         cty_shp = shp1.copy()        level   = 1        # Name of shapefile    # TODO: Make more efficient    nameshp = {        "countrycode": ["ARG", "BLZ", "BOL", "BRB", "CHL", "COL", "CRI", "DOM",                         "ECU", "GTM", "GUY", "HND", "JAM", "MEX", "NIC", "PAN",                         "PER", "PRY", "SLV", "TTO", "URY", "VEN"],        "geolevel"   : ["departamento", "district", "provincia", "parish",                         "provincia", "municipio", "cantón", "provincia",                        "cantón", "municipio", "subregion", "municipio", "parish",                         "municipio", "municipio", "distrito", "provincia", "distrito",                         "municipio", "level_1", "sección", "municipios"],        "shapefile"  : ["departamentos_WGS84_DI_8.shp", "district.shp",                         "limite_Provinciale_2004.shp", "geocarto00.shp",                         "Provincia_region.shp", "admin01.shp", "geocarto01.shp",                         "provincia.shp", "geolevel01.shp",                         "GU_Municipio_WGS84_DI8_region.shp", "GUY_geolevel01.shp",                         "level1.shp", "geocarto00.shp", "geocarto01.shp", "NIC_adm2.shp",                         "geocarto01.shp", "Provincias_region.shp", "geocarto01.shp",                         "geocarto01.shp", "comms.shp", "geocarto02.shp", "municipios.shp"]    }        # Create DataFrame    nameshp = pd.DataFrame(nameshp)        # Shapefile    # TODO: update path    file     = nameshp.loc[nameshp.countrycode == code,'shapefile'].item()    file     = f'{base}/raw/desinventar/_misc/DI_export_{code.lower()}/{file}'    shp_data = gpd.read_file(file)    shp_data = shp_data.set_crs(cty_shp.crs)        # Merge     vars_ = ['level0','level1','level2']    data1 = shp_data.drop(columns = "geometry")    data2 = xml_data[vars_]    var1, var2 = find_best_match(data1, data2, priority_vars = vars_)        # Preprocess variables    xml_vars = ['serial','level0','level1','level2','evento','fechano','muertos','heridos','desaparece','afectados','vivdest','vivafec']    xml_data = xml_data[xml_vars]    xml_data['evento']   = xml_data['evento'].str.lower()    xml_data['evento']   = xml_data['evento'].astype(str).apply(normalize_text)    xml_data['fechano']  = xml_data['fechano'].astype(int)     xml_data['min_anio'] = xml_data.fechano.min()    xml_data['max_anio'] = xml_data.fechano.max()        # Define variables of interest    xml_data['DESASTRES_TOT'] = 1    xml_data['DESASTRES_5Y']  = np.where(xml_data.fechano > xml_data.fechano.max() - 5 , 1, 0)    xml_data['DESASTRES_10Y'] = np.where(xml_data.fechano > xml_data.fechano.max() - 10, 1, 0)        # Object to numeric    cols = ['muertos','heridos','desaparece','afectados','vivdest','vivafec']    xml_data[cols] = xml_data[cols].apply(pd.to_numeric, errors = 'coerce')        # Intersection betwene shapefiles    shp = gpd.sjoin(shp_data, cty_shp, how = 'left', predicate = 'intersects')    shp = shp.reset_index(drop = True)    shp = shp.dropna(subset = ['index_right'])        # Adjust geometry    cty_shp ['geometry'] = cty_shp ['geometry'].buffer(0)    shp_data['geometry'] = shp_data['geometry'].buffer(0)    shp     ['geometry'] = shp     ['geometry'].buffer(0)        # Identify ADMIN code     shp['int_area'] = shp.apply(lambda row: row.geometry.intersection(cty_shp.loc[row['index_right']].geometry).area, axis = 1)    shp = shp.loc[shp.groupby(var1)['int_area'].idxmax()]    shp = shp[[var1, f"ADM{level}_PCODE"]]          # Final data    data = xml_data.merge(shp, left_on = var2, right_on = var1)    data['ADM0_EN'] = code    data = data[['ADM0_EN',f'ADM{level}_PCODE',                 'serial',                 'evento','fechano','min_anio','max_anio',                 'DESASTRES_TOT','DESASTRES_5Y','DESASTRES_10Y',                 'muertos','heridos','desaparece','afectados','vivdest','vivafec']]        # Dataframe at the year-admin-event level    return datadef get_emdat():    return def get_desastres():    return 