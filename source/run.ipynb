{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0e7978",
   "metadata": {},
   "source": [
    "# Social infrastructure in LAC\n",
    "\n",
    "**Objetive:** <br>\n",
    "The following notebook runs all the social infrastructure analysis. <br>\n",
    "\n",
    "Author: Laura Goyeneche, Consultant SPH, lauragoy@iadb.org <br>\n",
    "Created: March 20, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788875ad",
   "metadata": {},
   "source": [
    "## 1. Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31958d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install h3\n",
    "\n",
    "\"Manuals and Standards/IADB country and area codes for statistical use/IADB_country_codes_admin_1.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4917309",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Import modules \n",
    "import fiona \n",
    "from utils import * \n",
    "\n",
    "from h3 import geo_to_h3, h3_to_geo_boundary\n",
    "from shapely.geometry import Polygon\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfda062",
   "metadata": {},
   "source": [
    "## 2. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05a82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine input values\n",
    "data   = get_iadb()\n",
    "codes  = data.isoalpha3.tolist()\n",
    "groups = [\"total_population\",\"women\",\"men\",\"children_under_five\",\"youth_15_24\",\"elderly_60_plus\",\"women_of_reproductive_age_15_49\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb54421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefiles \n",
    "shp1 = get_country_shp(level = 1)\n",
    "shp2 = get_country_shp(level = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d6d97",
   "metadata": {},
   "source": [
    "## 3. Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Inputs\n",
    "group = \"total_population\"\n",
    "code  = \"BRA\"\n",
    "\n",
    "# Get population data \n",
    "file = get_population(data, code, group)\n",
    "\n",
    "# Save data \n",
    "file.to_csv(f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\", compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total population by adminsitrative level\n",
    "group        = \"total_population\"\n",
    "pop_shp1_lac = []\n",
    "pop_shp2_lac = []\n",
    "\n",
    "for code in codes[:-1]: \n",
    "    print(code)\n",
    "    # Population Meta-level\n",
    "    population = pd.read_csv(f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\")\n",
    "    geometry   = gpd.points_from_xy(population['longitude'], population['latitude'])\n",
    "    population = gpd.GeoDataFrame(population.copy(), geometry = geometry, crs = 4326)\n",
    "\n",
    "    # Population in admin level 1\n",
    "    pop_shp1 = gpd.sjoin(shp1[shp1.ADM0_PCODE == code], population)\n",
    "    pop_shp1 = pop_shp1[[\"ADM1_PCODE\",\"population\"]]\n",
    "    pop_shp1 = pop_shp1.groupby(\"ADM1_PCODE\").sum().reset_index()\n",
    "    \n",
    "    # Population in admin level 2\n",
    "    pop_shp2 = gpd.sjoin(shp2[shp2.ADM0_PCODE == code], population)\n",
    "    pop_shp2 = pop_shp2[[\"ADM2_PCODE\",\"population\"]]\n",
    "    pop_shp2 = pop_shp2.groupby(\"ADM2_PCODE\").sum().reset_index()\n",
    "    \n",
    "    # Append to master lists\n",
    "    pop_shp1_lac.append(pop_shp1)\n",
    "    pop_shp2_lac.append(pop_shp2)\n",
    "\n",
    "pop_shp1_lac = pd.concat(pop_shp1_lac)\n",
    "pop_shp2_lac = pd.concat(pop_shp2_lac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953293af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export population datasets\n",
    "    # Admin 1\n",
    "shp1_ = shp1.drop(columns = \"geometry\")\n",
    "shp1_ = shp1_.merge(pop_shp1_lac, on = \"ADM1_PCODE\", how = \"left\")\n",
    "shp1_.to_csv(f\"../data/0-raw/population/{group}/population-adm1.csv\", index = False)\n",
    "\n",
    "    # Admin 2\n",
    "shp2_ = shp2.drop(columns = \"geometry\")\n",
    "shp2_ = shp2_.merge(pop_shp2_lac, on = \"ADM2_PCODE\", how = \"left\")\n",
    "shp2_.to_csv(f\"../data/0-raw/population/{group}/population-adm2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe882f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN\n",
    "# Datafile save in wrong format \n",
    "%%capture\n",
    "for group in groups:\n",
    "    for code in codes[:1]:\n",
    "        data = f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\"\n",
    "        data = pd.read_csv(data)\n",
    "        path = \"Development Data Partnership/Facebook - High resolution population density map/public-fb-data/csv/\"\n",
    "        path = scldatalake + f\"{path}/{code.upper()}/{code}_{group}.csv.gz\"\n",
    "        data.to_csv(path, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb218e1",
   "metadata": {},
   "source": [
    "## 4. Amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5e8a2",
   "metadata": {},
   "source": [
    "### 4.1. Extract coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e06a3",
   "metadata": {},
   "source": [
    "#### Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07665b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset \n",
    "client  = Socrata(\"www.datos.gov.co\", None)\n",
    "request = client.get(\"c36g-9fc2\", limit = 100000)\n",
    "file    = pd.DataFrame.from_records(request)\n",
    "file    = file[file.claseprestador == 'Instituciones Prestadoras de Servicios de Salud - IPS']\n",
    "file    = file.drop_duplicates()\n",
    "file    = file.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define address\n",
    "file[\"address\"] = file[['direcci_nsede','departamentodededesc','municipiosededesc']].agg(' '.join, axis = 1)\n",
    "file[\"address\"] = file.address.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9af0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find coordinates \n",
    "coordinates = []\n",
    "for name in file.address:\n",
    "    coordinates_ = get_coordinates(name, \"COL\")\n",
    "    coordinates.append(coordinates_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select coordinates and find lat,lon\n",
    "lat, lon = [], []\n",
    "for i in range(0,len(coordinates)):\n",
    "    coordinate = coordinates[i]\n",
    "    if len(coordinate) > 1:\n",
    "        coordinate = [j for j in coordinate if file.departamentodededesc[i]      in j[\"place_name\"]]\n",
    "        coordinate = [j for j in coordinate if file.municipiosededesc[i].title() in j[\"place_name\"]] \n",
    "        if len(coordinate) > 1:\n",
    "            coordinate = coordinate[:1]\n",
    "    try:\n",
    "        coordinate = coordinate[0]['geometry']\n",
    "        lon_, lat_ = coordinate['coordinates']\n",
    "    except:\n",
    "        lon_, lat_ = '', ''\n",
    "    \n",
    "    lat.append(lat_)\n",
    "    lon.append(lon_) \n",
    "\n",
    "file['latitute']  = lat\n",
    "file['longitude'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to SCL\n",
    "file.to_csv(f\"{scldatalake}Geospatial infrastructure/Healthcare Facilities/official/COL/reps-ips.csv\", index = False, encoding = 'uft-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26549f",
   "metadata": {},
   "source": [
    "### 4.2. Master infrastrastructure table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fccbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "amenities = ['healthcare','financial']\n",
    "groups    = [\"official\",\"public\"]\n",
    "for group in groups[:1]:\n",
    "    for amenity in amenities[:1]:\n",
    "        # Get infrastructure data\n",
    "        infrastructure = get_amenity(amenity, group)\n",
    "        \n",
    "        if len(infrastructure) > 0:\n",
    "            infrastructure.to_csv(f\"../data/0-raw/infrastructure/{amenity}_facilities_{group}.csv\")\n",
    "            infrastructure.to_csv(f\"{scldatalake}Geospatial infrastructure/{amenity.title()} Facilities/{amenity}_facilities_{group}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee57f2",
   "metadata": {},
   "source": [
    "## 4. Isochrones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb24aa",
   "metadata": {},
   "source": [
    "### 4.1 Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "477a3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 minutes\n",
      "CPU times: user 3min 14s, sys: 5.75 s, total: 3min 20s\n",
      "Wall time: 8min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Inputs\n",
    "amenity = 'healthcare'\n",
    "minute  = 15\n",
    "profile = 'walking'\n",
    "group   = \"official\"\n",
    "code    = \"COL\"\n",
    "\n",
    "# Get isochrones per amenity\n",
    "print(f\"{minute} minutes\")\n",
    "isochrone = get_isochrones_country(code, amenity, minute, profile, group)\n",
    "isochrone['geometry'] = isochrone.geometry.buffer(0)\n",
    "isochrones = isochrone.dissolve()\n",
    "\n",
    "# Export isochrone\n",
    "isochrones.to_file(f\"../data/1-isochrones/{amenity}/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29f1c4",
   "metadata": {},
   "source": [
    "### 4.2 Financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# Inputs\n",
    "amenity = 'financial'\n",
    "group   = \"public\"\n",
    "minute  = 30\n",
    "profile = 'driving'\n",
    "code    = \"GUY\"\n",
    "\n",
    "# Get isochrones per amenity\n",
    "isochrone  = get_isochrones_country(code, amenity, minute, profile, group)\n",
    "isochrones = isochrone.dissolve()\n",
    "\n",
    "# Export isochrone \n",
    "isochrones.to_file(f\"../data/1-isochrones/{amenity}/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each financial service type\n",
    "for category in isochrone.amenity.unique():\n",
    "    # Create one multipolygon\n",
    "    isochrones = isochrone[isochrone.amenity == category]\n",
    "    isochrones = isochrones.dissolve()\n",
    "\n",
    "    # Export isochrone \n",
    "    isochrones.to_file(f\"../data/1-isochrones/{amenity}/{category}/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131c51e",
   "metadata": {},
   "source": [
    "### 4.3 Regional shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7dada",
   "metadata": {},
   "source": [
    "#### 4.3.1 Individual regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1baf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "amenity    = \"healthcare\"\n",
    "profile    = \"driving\"\n",
    "minute     = 30\n",
    "group      = \"official\"\n",
    "isochrones = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40461253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of country-isochrones\n",
    "# Note: Try/except for countries without isochrones\n",
    "for code in codes:\n",
    "    try:\n",
    "        with fiona.Env(OGR_GEOJSON_MAX_OBJ_SIZE = 2000):  \n",
    "            isochrone = gpd.read_file(f\"../data/1-isochrones/{amenity}/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\")\n",
    "            isochrones.append(isochrone)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbddf867",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create regional isochrone\n",
    "isochrones = pd.concat(isochrones)\n",
    "isochrones = isochrones.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f532ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export isochrones \n",
    "isochrones.to_file(f\"../data/1-isochrones/region/{amenity}/{group}/{minute}-min/{amenity}-{profile}-{minute}.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ab18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (20,8))\n",
    "shp1.plot(ax = ax, color = \"#D6D6D6\")\n",
    "isochrones.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eacc06",
   "metadata": {},
   "source": [
    "#### 4.3.2 Joint regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de39110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs \n",
    "amenity = \"healthcare\"\n",
    "profile = \"driving\"\n",
    "region_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b845dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create joint shapefile\n",
    "minutes = [15, 30, 45]\n",
    "for minute in minutes:\n",
    "    temp = gpd.read_file(f\"../data/1-isochrones/region/{amenity}-{profile}-{minute}.shp\")\n",
    "    temp[\"minute\"] = minute\n",
    "    region_.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac1e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regional isochrone\n",
    "region_ = pd.concat(region_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export isochrones \n",
    "region_.to_file(f\"../data/1-isochrones/{amenity}-{profile}.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaddebb",
   "metadata": {},
   "source": [
    "## 5. Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c695a3",
   "metadata": {},
   "source": [
    "### 5.1. Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1acedfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 55s, sys: 7.78 s, total: 42min 2s\n",
      "Wall time: 42min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Inputs\n",
    "amenity = 'healthcare'\n",
    "minute  = 15\n",
    "profile = 'walking'\n",
    "group   = \"official\"\n",
    "code    = \"COL\"\n",
    "\n",
    "# Create shapefile\n",
    "adm2_, h3_ = get_coverage(code, amenity, profile, minute, group)\n",
    "\n",
    "# Export isochrone \n",
    "adm2_.to_file(f\"../data/2-coverage/{amenity}/adm2/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")\n",
    "h3_  .to_file(f\"../data/2-coverage/{amenity}/h3/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\"  , driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8e60e",
   "metadata": {},
   "source": [
    "### 5.2. Financieros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "amenity    = 'financial'\n",
    "subamenity = {\"all\":[\"\",\"total\"],\"atm\":[\"atm\",\"atm\"],\"bank\":[\"bank\",\"bank\"],\"bureau_de_change\":[\"bureau_de_change\",\"bureau_de_change\"]}\n",
    "minute     = 30\n",
    "profile    = 'driving'\n",
    "code       = \"BRA\"\n",
    "\n",
    "#for amenity_ in subamenity.keys():\n",
    "for amenity_ in [\"bank\",\"bureau_de_change\"]:\n",
    "    # Labels \n",
    "    amenity_input  = f\"{amenity}/{subamenity[amenity_][0]}\"\n",
    "    amenity_input  = re.sub(\"/$\",\"\",amenity_input)\n",
    "    amenity_output = f\"{amenity}/{subamenity[amenity_][1]}\"\n",
    "\n",
    "    # Create shapefile\n",
    "    adm2_, h3_ = get_coverage(code, amenity_input, profile, minute)\n",
    "\n",
    "    # Export isochrone\n",
    "    adm2_.to_file(f\"../data/2-coverage/{amenity_output}/adm2/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")\n",
    "    h3_  .to_file(f\"../data/2-coverage/{amenity_output}/h3/{code}-{profile}-{minute}.geojson\"  , driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d32e71",
   "metadata": {},
   "source": [
    "### 5.3. Create regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44095d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefile ADMIN-2\n",
    "file = f\"Geospatial Basemaps/Cartographic Boundary Files/LAC-26/region/level-2/lac-level-2.shp\"\n",
    "path = scldatalake + file\n",
    "shp  = gpd.read_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73c2e3",
   "metadata": {},
   "source": [
    "#### 5.3.1. Healthcare amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a86c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create public and official regional shp\n",
    "# Inputs \n",
    "unit  = \"h3\"\n",
    "group = \"official\"\n",
    "min_  = 30\n",
    "\n",
    "# Append datasets\n",
    "path  = f\"../data/2-coverage/healthcare/{unit}/{group}/{min_}-min\"\n",
    "file  = os.listdir(path)\n",
    "file  = [name for name in file if \"geojson\" in name]\n",
    "shp_  = [gpd.read_file(f\"{path}/{name}\") for name in file]\n",
    "lac   = gpd.pd.concat(shp_).pipe(gpd.GeoDataFrame)\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/{group}/lac-driving-{min_}-min.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Join public and official amenities\n",
    "unit     = \"h3\"\n",
    "minute   = 30\n",
    "\n",
    "# Import data\n",
    "public   = gpd.read_file(f\"../data/2-coverage/healthcare/{unit}/public/lac-driving-{minute}-min.geojson\")\n",
    "official = gpd.read_file(f\"../data/2-coverage/healthcare/{unit}/official/lac-driving-{minute}-min.geojson\")\n",
    "\n",
    "# Rename variables \n",
    "# Note: rename variables for Atlas IADB (max elength 11 letters)\n",
    "names    = {\"pop_cov\":\"ncov\",\"pop_uncov\":\"nuncov\",\"per_cov\":\"ratecov\",\"per_uncov\":\"rateunc\"}\n",
    "public   = public  .rename(columns = names)\n",
    "official = official.rename(columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c18baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "if unit == \"h3\":\n",
    "    shp0     = get_country_shp(level = 0)   \n",
    "    public   = gpd.sjoin(public  , shp0)\n",
    "    official = gpd.sjoin(official, shp0)\n",
    "    \n",
    "    public   = public  .drop(columns = \"index_right\")\n",
    "    official = official.drop(columns = \"index_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c06e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create new featutes \n",
    "    # Public data\n",
    "public[\"percov\"] = public.ncov   * 100 / public.groupby(\"ADM0_PCODE\").ncov  .transform(\"sum\")\n",
    "public[\"perunc\"] = public.nuncov * 100 / public.groupby(\"ADM0_PCODE\").nuncov.transform(\"sum\")\n",
    "\n",
    "    # Official data\n",
    "official[\"percov\"] = official.ncov   * 100 / official.groupby(\"ADM0_PCODE\").ncov  .transform(\"sum\")\n",
    "official[\"perunc\"] = official.nuncov * 100 / official.groupby(\"ADM0_PCODE\").nuncov.transform(\"sum\")\n",
    "\n",
    "# Define columns names\n",
    "colnames   = public.columns.tolist()\n",
    "vars_      = ['ncov','nuncov','ratecov','rateunc','percov','perunc']\n",
    "pub_vars   = [f\"{name}_pub\" if name in vars_ else name for name in colnames]\n",
    "off_vars   = [f\"{name}_off\" if name in vars_ else name for name in colnames]\n",
    "\n",
    "# Rename variables\n",
    "public  .columns = pub_vars\n",
    "official.columns = off_vars\n",
    "\n",
    "# Drop columns from official dataset\n",
    "idvar    = \"ADM2_PCODE\" if unit == \"adm2\" else \"hex_id\"\n",
    "off_vars = [idvar] + [name for name in official.columns if \"_off\" in name] \n",
    "official = official[off_vars]\n",
    "\n",
    "# Merge \n",
    "lac = public.merge(official, on = idvar, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa446f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add poverty data and adjust names if admin-2\n",
    "# TODO: not neccesary, temporary, remove in other version\n",
    "if unit == \"adm2\":\n",
    "    # Import poverty data \n",
    "    path    = \"Data Projects/Official Subnational Poverty Rates/lac-level-2.csv\"\n",
    "    poverty = pd.read_csv(f\"s3://{sclbucket}/{path}\", encoding='latin-1')\n",
    "    poverty = poverty[[\"ADM2_PCODE\",\"POVERTY_RATE_TOT\",\"POVERTY_NUM_TOT\",\"POVERTY_SOURCE\"]]\n",
    "    poverty = poverty.rename(columns = {\"POVERTY_RATE_TOT\":\"pov_rate\",\"POVERTY_NUM_TOT\":\"pov_num\",\"POVERTY_SOURCE\":\"pov_source\"})\n",
    "    \n",
    "    # Merge \n",
    "    lac = lac.merge(poverty, on = \"ADM2_PCODE\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "lac = lac.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0faae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export data (GeoJSON, .shp, .csv)\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.geojson\", driver = \"GeoJSON\")\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.shp\")\n",
    "lac.drop(columns = \"geometry\").to_csv(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
