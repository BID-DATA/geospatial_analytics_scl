{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403daee8",
   "metadata": {},
   "source": [
    "# Social infrastructure in LAC\n",
    "\n",
    "**Objetive:** <br>\n",
    "The following notebook runs all the social infrastructure analysis. <br>\n",
    "\n",
    "Author: Laura Goyeneche, Consultant SPH, lauragoy@iadb.org <br>\n",
    "Created: March 20, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd548eff",
   "metadata": {},
   "source": [
    "## 1. Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Import modules \n",
    "import fiona \n",
    "from utils import * \n",
    "from h3 import geo_to_h3, h3_to_geo_boundary\n",
    "from shapely.geometry import Polygon\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef41b8c",
   "metadata": {},
   "source": [
    "## 2. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3daf81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine input values\n",
    "data   = get_iadb()\n",
    "codes  = data.isoalpha3.tolist()\n",
    "groups = [\"total_population\",\"women\",\"men\",\"children_under_five\",\"youth_15_24\",\"elderly_60_plus\",\"women_of_reproductive_age_15_49\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d513415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefiles \n",
    "shp1 = get_country_shp(level = 1)\n",
    "shp2 = get_country_shp(level = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac2563",
   "metadata": {},
   "source": [
    "## 3. Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Inputs\n",
    "group = \"total_population\"\n",
    "code  = \"BRA\"\n",
    "\n",
    "# Get population data \n",
    "file = get_population(data, code, group)\n",
    "\n",
    "# Save data \n",
    "file.to_csv(f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\", compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef20184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total population by adminsitrative level\n",
    "group        = \"total_population\"\n",
    "pop_shp1_lac = []\n",
    "pop_shp2_lac = []\n",
    "\n",
    "for code in codes[:-1]: \n",
    "    print(code)\n",
    "    # Population Meta-level\n",
    "    population = pd.read_csv(f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\")\n",
    "    geometry   = gpd.points_from_xy(population['longitude'], population['latitude'])\n",
    "    population = gpd.GeoDataFrame(population.copy(), geometry = geometry, crs = 4326)\n",
    "\n",
    "    # Population in admin level 1\n",
    "    pop_shp1 = gpd.sjoin(shp1[shp1.ADM0_PCODE == code], population)\n",
    "    pop_shp1 = pop_shp1[[\"ADM1_PCODE\",\"population\"]]\n",
    "    pop_shp1 = pop_shp1.groupby(\"ADM1_PCODE\").sum().reset_index()\n",
    "    \n",
    "    # Population in admin level 2\n",
    "    pop_shp2 = gpd.sjoin(shp2[shp2.ADM0_PCODE == code], population)\n",
    "    pop_shp2 = pop_shp2[[\"ADM2_PCODE\",\"population\"]]\n",
    "    pop_shp2 = pop_shp2.groupby(\"ADM2_PCODE\").sum().reset_index()\n",
    "    \n",
    "    # Append to master lists\n",
    "    pop_shp1_lac.append(pop_shp1)\n",
    "    pop_shp2_lac.append(pop_shp2)\n",
    "\n",
    "pop_shp1_lac = pd.concat(pop_shp1_lac)\n",
    "pop_shp2_lac = pd.concat(pop_shp2_lac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e58849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export population datasets\n",
    "    # Admin 1\n",
    "shp1_ = shp1.drop(columns = \"geometry\")\n",
    "shp1_ = shp1_.merge(pop_shp1_lac, on = \"ADM1_PCODE\", how = \"left\")\n",
    "shp1_.to_csv(f\"../data/0-raw/population/{group}/population-adm1.csv\", index = False)\n",
    "\n",
    "    # Admin 2\n",
    "shp2_ = shp2.drop(columns = \"geometry\")\n",
    "shp2_ = shp2_.merge(pop_shp2_lac, on = \"ADM2_PCODE\", how = \"left\")\n",
    "shp2_.to_csv(f\"../data/0-raw/population/{group}/population-adm2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN\n",
    "# Datafile save in wrong format \n",
    "%%capture\n",
    "for group in groups:\n",
    "    for code in codes[:1]:\n",
    "        data = f\"../data/0-raw/population/{group}/{code}_{group}.csv.gz\"\n",
    "        data = pd.read_csv(data)\n",
    "        path = \"Development Data Partnership/Facebook - High resolution population density map/public-fb-data/csv/\"\n",
    "        path = scldatalake + f\"{path}/{code.upper()}/{code}_{group}.csv.gz\"\n",
    "        data.to_csv(path, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baccf96a",
   "metadata": {},
   "source": [
    "## 4. Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bde02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "amenities = ['healthcare','financial']\n",
    "groups    = [\"official\",\"public\"]\n",
    "for group in groups:\n",
    "    for amenity in amenities:\n",
    "        # Get infrastructure data\n",
    "        infrastructure = get_amenity(amenity, group)\n",
    "        \n",
    "        if len(infrastructure) > 0:\n",
    "            infrastructure.to_csv(f\"../data/0-raw/infrastructure/{amenity}_facilities_{group}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310587f5",
   "metadata": {},
   "source": [
    "## 4. Isochrones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0abc9",
   "metadata": {},
   "source": [
    "### 4.1 Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Inputs\n",
    "amenity = 'healthcare'\n",
    "minute  = 30\n",
    "profile = 'driving'\n",
    "group   = \"official\"\n",
    "code    = \"BRA\"\n",
    "\n",
    "# Get isochrones per amenity\n",
    "isochrone = get_isochrones_country(code, amenity, minute, profile, group)\n",
    "isochrone['geometry'] = isochrone.geometry.buffer(0)\n",
    "isochrones = isochrone.dissolve()\n",
    "\n",
    "# Export isochrone\n",
    "isochrones.to_file(f\"../data/1-isochrones/{amenity}/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34cbc5",
   "metadata": {},
   "source": [
    "### 4.2 Financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# Inputs\n",
    "amenity = 'financial'\n",
    "group   = \"public\"\n",
    "minute  = 30\n",
    "profile = 'driving'\n",
    "code    = \"GUY\"\n",
    "\n",
    "# Get isochrones per amenity\n",
    "isochrone  = get_isochrones_country(code, amenity, minute, profile, group)\n",
    "isochrones = isochrone.dissolve()\n",
    "\n",
    "# Export isochrone \n",
    "isochrones.to_file(f\"../data/1-isochrones/{amenity}/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each financial service type\n",
    "for category in isochrone.amenity.unique():\n",
    "    # Create one multipolygon\n",
    "    isochrones = isochrone[isochrone.amenity == category]\n",
    "    isochrones = isochrones.dissolve()\n",
    "\n",
    "    # Export isochrone \n",
    "    isochrones.to_file(f\"../data/1-isochrones/{amenity}/{category}/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca3c5a",
   "metadata": {},
   "source": [
    "### 4.3 Regional shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e05965",
   "metadata": {},
   "source": [
    "#### 4.3.1 Individual regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "amenity    = \"healthcare\"\n",
    "profile    = \"driving\"\n",
    "minute     = 30\n",
    "group      = \"official\"\n",
    "isochrones = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e39e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of country-isochrones\n",
    "# Note: Try/except for countries without isochrones\n",
    "for code in codes:\n",
    "    try:\n",
    "        with fiona.Env(OGR_GEOJSON_MAX_OBJ_SIZE = 2000):  \n",
    "            isochrone = gpd.read_file(f\"../data/1-isochrones/{amenity}/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\")\n",
    "            isochrones.append(isochrone)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af578d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create regional isochrone\n",
    "isochrones = pd.concat(isochrones)\n",
    "isochrones = isochrones.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aef95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export isochrones \n",
    "isochrones.to_file(f\"../data/1-isochrones/region/{amenity}/{group}/{minute}-min/{amenity}-{profile}-{minute}.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8056756",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (20,8))\n",
    "shp1.plot(ax = ax, color = \"#D6D6D6\")\n",
    "isochrones.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c2ef5",
   "metadata": {},
   "source": [
    "#### 4.3.2 Joint regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95449cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs \n",
    "amenity = \"healthcare\"\n",
    "profile = \"driving\"\n",
    "region_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ebf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create joint shapefile\n",
    "minutes = [15, 30, 45]\n",
    "for minute in minutes:\n",
    "    temp = gpd.read_file(f\"../data/1-isochrones/region/{amenity}-{profile}-{minute}.shp\")\n",
    "    temp[\"minute\"] = minute\n",
    "    region_.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1aa3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regional isochrone\n",
    "region_ = pd.concat(region_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export isochrones \n",
    "region_.to_file(f\"../data/1-isochrones/{amenity}-{profile}.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d700c9",
   "metadata": {},
   "source": [
    "## 5. Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23829a6",
   "metadata": {},
   "source": [
    "### 5.1. Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Inputs\n",
    "amenity = 'healthcare'\n",
    "minute  = 30\n",
    "profile = 'driving'\n",
    "group   = \"official\"\n",
    "code    = \"BRA\"\n",
    "\n",
    "# Create shapefile\n",
    "adm2_, h3_ = get_coverage(code, amenity, profile, minute, group)\n",
    "\n",
    "# Export isochrone \n",
    "adm2_.to_file(f\"../data/2-coverage/{amenity}/adm2/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")\n",
    "h3_  .to_file(f\"../data/2-coverage/{amenity}/h3/{group}/{minute}-min/{code}-{profile}-{minute}.geojson\"  , driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb008c0",
   "metadata": {},
   "source": [
    "### 5.2. Financieros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63148ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "amenity    = 'financial'\n",
    "subamenity = {\"all\":[\"\",\"total\"],\"atm\":[\"atm\",\"atm\"],\"bank\":[\"bank\",\"bank\"],\"bureau_de_change\":[\"bureau_de_change\",\"bureau_de_change\"]}\n",
    "minute     = 30\n",
    "profile    = 'driving'\n",
    "code       = \"BRA\"\n",
    "\n",
    "#for amenity_ in subamenity.keys():\n",
    "for amenity_ in [\"bank\",\"bureau_de_change\"]:\n",
    "    # Labels \n",
    "    amenity_input  = f\"{amenity}/{subamenity[amenity_][0]}\"\n",
    "    amenity_input  = re.sub(\"/$\",\"\",amenity_input)\n",
    "    amenity_output = f\"{amenity}/{subamenity[amenity_][1]}\"\n",
    "\n",
    "    # Create shapefile\n",
    "    adm2_, h3_ = get_coverage(code, amenity_input, profile, minute)\n",
    "\n",
    "    # Export isochrone\n",
    "    adm2_.to_file(f\"../data/2-coverage/{amenity_output}/adm2/{code}-{profile}-{minute}.geojson\", driver = \"GeoJSON\")\n",
    "    h3_  .to_file(f\"../data/2-coverage/{amenity_output}/h3/{code}-{profile}-{minute}.geojson\"  , driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60778bb0",
   "metadata": {},
   "source": [
    "### 5.3. Create regional shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1005e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefile ADMIN-2\n",
    "file = f\"Geospatial Basemaps/Cartographic Boundary Files/LAC-26/region/level-2/lac-level-2.shp\"\n",
    "path = scldatalake + file\n",
    "shp  = gpd.read_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f186d",
   "metadata": {},
   "source": [
    "#### 5.3.1. Healthcare amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aad371",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create public and official regional shp\n",
    "# Inputs \n",
    "unit  = \"h3\"\n",
    "group = \"official\"\n",
    "min_  = 30\n",
    "\n",
    "# Append datasets\n",
    "path  = f\"../data/2-coverage/healthcare/{unit}/{group}/{min_}-min\"\n",
    "file  = os.listdir(path)\n",
    "file  = [name for name in file if \"geojson\" in name]\n",
    "shp_  = [gpd.read_file(f\"{path}/{name}\") for name in file]\n",
    "lac   = gpd.pd.concat(shp_).pipe(gpd.GeoDataFrame)\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/{group}/lac-driving-{min_}-min.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Join public and official amenities\n",
    "unit     = \"h3\"\n",
    "minute   = 30\n",
    "\n",
    "# Import data\n",
    "public   = gpd.read_file(f\"../data/2-coverage/healthcare/{unit}/public/lac-driving-{minute}-min.geojson\")\n",
    "official = gpd.read_file(f\"../data/2-coverage/healthcare/{unit}/official/lac-driving-{minute}-min.geojson\")\n",
    "\n",
    "# Rename variables \n",
    "# Note: rename variables for Atlas IADB (max elength 11 letters)\n",
    "names    = {\"pop_cov\":\"ncov\",\"pop_uncov\":\"nuncov\",\"per_cov\":\"ratecov\",\"per_uncov\":\"rateunc\"}\n",
    "public   = public  .rename(columns = names)\n",
    "official = official.rename(columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "if unit == \"h3\":\n",
    "    shp0     = get_country_shp(level = 0)   \n",
    "    public   = gpd.sjoin(public  , shp0)\n",
    "    official = gpd.sjoin(official, shp0)\n",
    "    \n",
    "    public   = public  .drop(columns = \"index_right\")\n",
    "    official = official.drop(columns = \"index_right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e28404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create new featutes \n",
    "    # Public data\n",
    "public[\"percov\"] = public.ncov   * 100 / public.groupby(\"ADM0_PCODE\").ncov  .transform(\"sum\")\n",
    "public[\"perunc\"] = public.nuncov * 100 / public.groupby(\"ADM0_PCODE\").nuncov.transform(\"sum\")\n",
    "\n",
    "    # Official data\n",
    "official[\"percov\"] = official.ncov   * 100 / official.groupby(\"ADM0_PCODE\").ncov  .transform(\"sum\")\n",
    "official[\"perunc\"] = official.nuncov * 100 / official.groupby(\"ADM0_PCODE\").nuncov.transform(\"sum\")\n",
    "\n",
    "# Define columns names\n",
    "colnames   = public.columns.tolist()\n",
    "vars_      = ['ncov','nuncov','ratecov','rateunc','percov','perunc']\n",
    "pub_vars   = [f\"{name}_pub\" if name in vars_ else name for name in colnames]\n",
    "off_vars   = [f\"{name}_off\" if name in vars_ else name for name in colnames]\n",
    "\n",
    "# Rename variables\n",
    "public  .columns = pub_vars\n",
    "official.columns = off_vars\n",
    "\n",
    "# Drop columns from official dataset\n",
    "idvar    = \"ADM2_PCODE\" if unit == \"adm2\" else \"hex_id\"\n",
    "off_vars = [idvar] + [name for name in official.columns if \"_off\" in name] \n",
    "official = official[off_vars]\n",
    "\n",
    "# Merge \n",
    "lac = public.merge(official, on = idvar, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add poverty data and adjust names if admin-2\n",
    "# TODO: not neccesary, temporary, remove in other version\n",
    "if unit == \"adm2\":\n",
    "    # Import poverty data \n",
    "    path    = \"Data Projects/Official Subnational Poverty Rates/lac-level-2.csv\"\n",
    "    poverty = pd.read_csv(f\"s3://{sclbucket}/{path}\", encoding='latin-1')\n",
    "    poverty = poverty[[\"ADM2_PCODE\",\"POVERTY_RATE_TOT\",\"POVERTY_NUM_TOT\",\"POVERTY_SOURCE\"]]\n",
    "    poverty = poverty.rename(columns = {\"POVERTY_RATE_TOT\":\"pov_rate\",\"POVERTY_NUM_TOT\":\"pov_num\",\"POVERTY_SOURCE\":\"pov_source\"})\n",
    "    \n",
    "    # Merge \n",
    "    lac = lac.merge(poverty, on = \"ADM2_PCODE\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "lac = lac.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ef6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Export data (GeoJSON, .shp, .csv)\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.geojson\", driver = \"GeoJSON\")\n",
    "lac.to_file(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.shp\")\n",
    "lac.drop(columns = \"geometry\").to_csv(f\"../data/2-coverage/healthcare/{unit}/lac-driving-{min_}-min.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
